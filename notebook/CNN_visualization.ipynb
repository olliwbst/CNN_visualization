{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_visualization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "V5rE7Mimm7_c",
        "Kiy9Pk1hmKTb",
        "TTyVTLGVk3JA",
        "lEMBFkwqkowM",
        "R1ap54NzlS8R"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sit8KYA0mc9v",
        "colab_type": "text"
      },
      "source": [
        "Studying the effects of semantic segmentation of input images on CNN \n",
        "classification results using visualizations.\\\n",
        "bachelors thesis\n",
        "Oliver Wobst, 2020\n",
        "\n",
        "How to use:\\\n",
        "(during the steps, restart the runtime whenever promted to, then continue)\\\n",
        "-first off, connect to a runtime (top right, 'Connect')\\\n",
        "-set the runtime to GPU (only needed once)\\\n",
        "top left: Runtime-> Change runtime type-> set hardware accelerator to GPU\\\n",
        "-install the below packages from top to bottom\\\n",
        "-from this point the framework should be ready to go\\\n",
        "-open the runtimes filesystem by clicking the folder to the left\n",
        "\n",
        "hints:\\\n",
        "-tho its possible to upload the working files into the runtime directly\n",
        "it is advised to mount a drive as all 'local' files will be deleted once the\n",
        "runtime disconnects\\\n",
        "-the runtime times out being idle too long (no cells running)\\\n",
        "-in case you get OOM-errors restart the runtime, restarting wont cause you\n",
        "to lose local runtime files, only set variables in the cells\n",
        "Runtime->Restart runtime...(you also dont have to install the packages again)\\\n",
        "-in case you get errors with the checkpoints while training set the\n",
        "'monitor' variable in line 85 of the training-block to whatever the\n",
        "validation_accuracy is called in the post-epoch output of the cell\n",
        "(this may differ sometimes, but is usually something like\n",
        "'validation_acc' or 'val_acc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5rE7Mimm7_c",
        "colab_type": "text"
      },
      "source": [
        "# needed packages \n",
        "-execute those in order\\\n",
        "-needs to be done whenever the runtime is initialized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wltz2SkfnZwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.15.0  # ensures that this notebook uses tf 1.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmn3IfbvIAVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0 # optional until google colab upgrades global tf version to 2+"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QlBBHmGbFZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install https://github.com/raghakot/keras-vis/archive/master.zip\n",
        "!pip install innvestigate==1.0.8\n",
        "!pip install keras==2.3.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLqZ46Gro7gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kiy9Pk1hmKTb",
        "colab_type": "text"
      },
      "source": [
        "# DRIVE-IO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6qywUdmmQOP",
        "colab_type": "text"
      },
      "source": [
        "the following cell will promt you to sign into your google account and get parmission to mount the drive in this runtime "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5bR_CL_DETk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtArhOGGpwQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this zips the result-folder with all images before download\n",
        "!zip -r /content/results.zip /content/result_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ2yUROUpxUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this downloads the zipped folder from above\n",
        "from google.colab import files\n",
        "files.download(\"/content/results.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQU_2tr4k9Qq",
        "colab_type": "text"
      },
      "source": [
        "# PREPARATION-BLOCK\n",
        "even tho this block works in colab, IO is VERY slow. so is up/downloading\n",
        "several thousand sample images in the first place. it's way faster to\n",
        "execute this block on a local machine and upload the serialized .npy files\n",
        "to drive and continue with the TRAINING-BLOCK here.\n",
        "\n",
        "hint: to get paths in google colab just right click a file in the browser\n",
        "and choose copy path, that gives you the correct path in clipboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck5qwlR8tnNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "'''settable parameters start'''\n",
        "# raw-images paths\n",
        "# if no testdir available set it to None like this: test_DATADIR = None\n",
        "train_DATADIR = r'/content/drive/My Drive/cnn_datasets/AboveLayerShifting'\n",
        "test_DATADIR = None\n",
        "\n",
        "CATEGORIES = ['ClassA', 'ClassB']  # enter the names of the sub-directories for the classes (need to be exactly the same for testdir if available)\n",
        "\n",
        "# image adjustments\n",
        "IMG_SIZE = 213  # enter the desired pixelvalue fro with and height (thesis dataset-default is 384)\n",
        "IMG_DEPTH = 1  # enter image channels, 1=grayscale, 3=color\n",
        "validation_split = 0.2  # validation split in case there is no test-set yet (0.0..1.0)\n",
        "dataset_name = 'abovelayershifting'  # filename that goes in front of generated datasets\n",
        "'''settable parameters end'''\n",
        "\n",
        "training_data = []\n",
        "if test_DATADIR is not None:\n",
        "    test_data = []\n",
        "\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:\n",
        "\n",
        "        path = os.path.join(train_DATADIR, category)  # create path to set CATEGORIES-strings\n",
        "        class_num = CATEGORIES.index(category)  # get the classification by CATEGORIES-index\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image per A and B\n",
        "            try:\n",
        "                if IMG_DEPTH == 1:\n",
        "                    img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)  # convert to gs array\n",
        "                if IMG_DEPTH == 3:\n",
        "                    img_array = cv2.imread(os.path.join(path, img))  # convert to array\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "                training_data.append([new_array, class_num])  # add this to our training_data\n",
        "            except Exception as e:  # in case an image is faulty\n",
        "                pass\n",
        "        fig = plt.figure('sample for class {}'.format(category))\n",
        "        # the print is here for google colab, as it cant show the title there\n",
        "        print('sample for class {}'.format(category))\n",
        "        plotimg = cv2.cvtColor(new_array.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(plotimg)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def create_test_data():\n",
        "    for category in CATEGORIES:\n",
        "\n",
        "        path = os.path.join(test_DATADIR, category)\n",
        "        class_num = CATEGORIES.index(category)\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):\n",
        "            try:\n",
        "                if IMG_DEPTH == 1:\n",
        "                    img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                if IMG_DEPTH == 3:\n",
        "                    img_array = cv2.imread(os.path.join(path, img))\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                test_data.append([new_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "        fig = plt.figure('sample for class {}'.format(category))\n",
        "        # the print is here for google colab, as it cant show the title there\n",
        "        print('sample for class {}'.format(category))\n",
        "        plotimg = cv2.cvtColor(new_array.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(plotimg)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# MAKE TRAINSET\n",
        "print('creating training data...')\n",
        "create_training_data()\n",
        "\n",
        "print('training-samples: ', (len(training_data)))  # validate samplecount\n",
        "\n",
        "random.shuffle(training_data)  # randomize samples\n",
        "\n",
        "print('verify shuffling of traindata:')\n",
        "for sample in training_data[:10]:  # validate sample-shuffling\n",
        "    print(sample[1])\n",
        "\n",
        "# seperate images and labels\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "# bring images in final numpy-shape\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "\n",
        "# MAKE TESTSET\n",
        "if test_DATADIR is not None:\n",
        "    print('creating test data...')\n",
        "    create_test_data()\n",
        "\n",
        "    print('test-samples: ', len(test_data))\n",
        "\n",
        "    random.shuffle(test_data)\n",
        "\n",
        "    print('verify shuffling of testdata:')\n",
        "    for sample in test_data[:10]:\n",
        "        print(sample[1])\n",
        "\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "\n",
        "    for features, label in test_data:\n",
        "        X_test.append(features)\n",
        "        y_test.append(label)\n",
        "\n",
        "    X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "\n",
        "\n",
        "# slices the training-dataset to get a fraction of it (size set by split) as \n",
        "# testset\n",
        "def slice_dataset(split=0.2):\n",
        "    _x = len(X) * split\n",
        "    _x = int(_x)\n",
        "    xtest = X[-_x:]\n",
        "    ytest = y[-_x:]\n",
        "    xtrain = X[:(len(X)-_x)]\n",
        "    ytrain = y[:(len(y) - _x)]\n",
        "\n",
        "    return [xtrain, xtest, ytrain, ytest]\n",
        "\n",
        "\n",
        "# slice is only executed if test_DATADIR is set to None in global parameters\n",
        "if test_DATADIR is None:\n",
        "    sets = slice_dataset(validation_split)\n",
        "\n",
        "    X = sets[0]\n",
        "    X_test = sets[1]\n",
        "    y = sets[2]\n",
        "    y_test = sets[3]\n",
        "    print('sliced set, new values(X, X_test, y, y_test):', len(X), len(X_test), len(y), len(y_test))\n",
        "\n",
        "# saving the sets for training and testing, format with used parameters for easy distinguishing\n",
        "print('Saving data...')\n",
        "np.save('{}_X_train_{}_{}.npy'.format(dataset_name, IMG_SIZE, IMG_DEPTH), X)\n",
        "np.save('{}_y_train_{}_{}.npy'.format(dataset_name, IMG_SIZE, IMG_DEPTH), y)\n",
        "np.save('{}_X_test_{}_{}.npy'.format(dataset_name, IMG_SIZE, IMG_DEPTH), X_test)\n",
        "np.save('{}_y_test_{}_{}.npy'.format(dataset_name, IMG_SIZE, IMG_DEPTH), y_test)\n",
        "print('Saved data!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTyVTLGVk3JA",
        "colab_type": "text"
      },
      "source": [
        "# TRAINING-BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyc5bas9GccP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "'''settable parameters start'''\n",
        "TBNAME = 'tensorboard_metrics'  # name for tensorboard-file\n",
        "model_filepath = 'model_{epoch:02d}_{val_accuracy:.4f}.h5'  # change 'model' to somethign more descriptive of your set\n",
        "\n",
        "X_train_PATH = '/content/drive/My Drive/cnn_ready_data/mnist_X_28_1.npy'  # train-features\n",
        "y_train_PATH = '/content/drive/My Drive/cnn_ready_data/mnist_y_28_1.npy'  # train-labels\n",
        "\n",
        "X_test_PATH = '/content/drive/My Drive/cnn_ready_data/mnist_X_test_28_1.npy'  # test-features\n",
        "y_test_PATH = '/content/drive/My Drive/cnn_ready_data/mnist_y_test_28_1.npy'  # test-labels\n",
        "'''settable parameters end'''\n",
        "\n",
        "# trainingdata arrays, set the paths to the correct sets generated by data_preparation.py\n",
        "print('loading traindata...')\n",
        "X = np.load(X_train_PATH)\n",
        "y = np.load(y_train_PATH)\n",
        "print('length of traindata, needs to be equal: ', len(X), len(y))\n",
        "\n",
        "print('loading testdata...')\n",
        "X_test = np.load(X_test_PATH)\n",
        "y_test = np.load(y_test_PATH)\n",
        "print('length of testdata, needs to be equal: ', len(X_test), len(y_test))\n",
        "\n",
        "# reshape labels to support multiple classes\n",
        "y = keras.utils.to_categorical(y)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "X = X / 255.0  # normalize data because 255 is max pixelvalue\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "print('finished loading data...')\n",
        "\n",
        "'''MODEL STARTS HERE'''\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Block 1\n",
        "model.add(Conv2D(96, (3, 3),\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 name='block1_conv1',\n",
        "                 input_shape=X.shape[1:]))\n",
        "model.add(Conv2D(96, (3, 3),\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 name='block1_conv2'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Block 2\n",
        "model.add(Conv2D(96, (3, 3),\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 name='block2_conv1'))\n",
        "model.add(Conv2D(96, (3, 3),\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 name='block2_conv2'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Classification block\n",
        "model.add(Flatten(name='flatten'))\n",
        "model.add(Dense(128, activation='relu', name='fc1'))\n",
        "model.add(Dense(128, activation='relu', name='fc2'))\n",
        "model.add(Dense(2, activation='softmax', name='predictions'))\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.0001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "'''CALLBACKS'''\n",
        "# tensorboard\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(TBNAME))\n",
        "# tensorboard --logdir=logs/  to initialize the board from working dir\n",
        "\n",
        "# checkpoint\n",
        "checkpoint = ModelCheckpoint(model_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.fit(X, y,\n",
        "          batch_size=64,\n",
        "          epochs=40,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[tensorboard, checkpoint])\n",
        "\n",
        "'''MODEL ENDS HERE'''\n",
        "\n",
        "print('done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szMVwWEzllnV",
        "colab_type": "text"
      },
      "source": [
        "things to note:\n",
        "\n",
        "following things are mandatory for compatibility with the framework:\\\n",
        "-line 47, input_shape. leave as is (needs to be first layer)\\\n",
        "-line 71, activation need to stay softmax, number of neurons needs\\\n",
        "to be set to number of classes the problem has, in case you change the name\n",
        "also change it in visualization-block (settable parameters)\\\n",
        "-line 75, use a loss function that works with more than two classes\\\n",
        "-at least one maxpooled convlayer-combination where the conv before the pool can\n",
        "be used as gradCAM input-parameter, if multiple pooled conv use the one closest \n",
        "to final classification layer, here this would be 'block2_conv2' and set the\n",
        "parameter in visualization-block to same name again\\\n",
        "-if you want to use the layered_actmax function of visualization block you need\n",
        "to change the names of all layers you want to extract filters of manually for\n",
        "now so eighter set them like here for those layers or use print_summary() there\n",
        "to see the generated layernames\n",
        "\n",
        "everything besides that between the MODEL START and END tags is freely \n",
        "adjustable to the datasets needs\n",
        "\n",
        "the implemented combination of architecture and hyperparameters here has to be\n",
        "proven quite effective for relatively simple problems and, more importantly,\n",
        "works with all the visualization algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEMBFkwqkowM",
        "colab_type": "text"
      },
      "source": [
        "# VISUALIZATION-BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk_v4kHpsvs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from vis.utils import utils\n",
        "from vis.input_modifiers import Jitter\n",
        "from vis.visualization import visualize_cam, visualize_activation, visualize_saliency, get_num_filters\n",
        "import innvestigate.utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "\n",
        "'''settable parameters start'''\n",
        "'''paths'''\n",
        "model_PATH = '/content/drive/My Drive/cnn_models/graydog.h5'\n",
        "\n",
        "X_train_PATH = '/content/drive/My Drive/cnn_ready_data/graydog_features_50_1.npy'  # train-features\n",
        "y_train_PATH = '/content/drive/My Drive/cnn_ready_data/graydog_label_50_1.npy'  # train-labels\n",
        "\n",
        "X_test_PATH = '/content/drive/My Drive/cnn_ready_data/graydog_test_features_50_1.npy'  # test-features\n",
        "y_test_PATH = '/content/drive/My Drive/cnn_ready_data/graydog_test_label_50_1.npy'  # test-labels\n",
        "\n",
        "IMG_DIR = r'/content/result_images'  # img-directory for saving results\n",
        "\n",
        "'''lower this in case you run into problems (L.75-78)'''\n",
        "analyzer_batchsize = 32\n",
        "\n",
        "'''dont change the following unless you have a custom cnn-structure'''\n",
        "name_softmax_layer = 'predictions'  # used for vis-functions\n",
        "name_last_conv_layer = 'block2_conv2'  # used for gradcam-function\n",
        "layerlist_for_layered_actmax = ['block1_conv1', 'block1_conv2', 'block1_pool', \n",
        "                                'block2_conv1', 'block2_conv2', 'block2_pool',\n",
        "                                'fc1', 'fc2']  # used for layered actmax-function\n",
        "'''settable parameters end'''\n",
        "\n",
        "'''loading and reshaping data'''\n",
        "print('loading data...')\n",
        "model = keras.models.load_model(model_PATH)\n",
        "linear_model = keras.models.load_model(model_PATH)\n",
        "linear_model.layers[utils.find_layer_idx(linear_model, 'predictions')].activation = keras.activations.linear\n",
        "linear_model = utils.apply_modifications(linear_model)\n",
        "\n",
        "X_train = np.load(X_train_PATH)\n",
        "X_train = X_train / 255\n",
        "y_train = np.load(y_train_PATH)\n",
        "\n",
        "X_test = np.load(X_test_PATH)\n",
        "X_test = X_test / 255\n",
        "y_test = np.load(y_test_PATH)\n",
        "print('loaded data...')\n",
        "\n",
        "y_test = keras.utils.to_categorical(y_test)  # reshapes labels to categorical format\n",
        "IMG_SIZE = X_test.shape[1]  # sets to image dimensions for plotting equal to those of used data\n",
        "IMG_DEPTH = X_test.shape[3]  # getting information whether input data is grayscale (1) or color (3)\n",
        "\n",
        "'''creating result directory if it doesnt already exist by the set name'''\n",
        "if not os.path.exists(IMG_DIR):\n",
        "    os.mkdir(IMG_DIR)\n",
        "    print(\"Directory \", IMG_DIR,  \" created!\")\n",
        "else:\n",
        "    print(\"Directory \", IMG_DIR,  \" already exists, skipping.\")\n",
        "\n",
        "\n",
        "'''stripping softmax off of the model, needed for innvestigate functions'''\n",
        "def strip_softmax(_model):\n",
        "    _model = keras.models.Model(inputs=_model.get_input_at(0), outputs=_model.layers[-2].get_output_at(0))\n",
        "\n",
        "    return _model\n",
        "\n",
        "\n",
        "'''calculation analyzers for patternnet and patternattribution-functions'''\n",
        "print('calculating analysers...')\n",
        "pn_analyzer = innvestigate.create_analyzer('pattern.net', strip_softmax(model), **{\"pattern_type\": \"relu\"})\n",
        "pn_analyzer.fit(X_train, batch_size=analyzer_batchsize, verbose=1)\n",
        "pa_analyzer = innvestigate.create_analyzer('pattern.attribution', strip_softmax(model), **{\"pattern_type\": \"relu\"})\n",
        "pa_analyzer.fit(X_train, batch_size=analyzer_batchsize, verbose=1)\n",
        "print('calculated analysers...')\n",
        "\n",
        "'''checks compatibility of model and inputdatasets, adjusts them is incompatible\n",
        "should be run when you introduce different sets or run into numpy related \n",
        "compatibility-errors, this might solve them'''\n",
        "def reshape_testset():\n",
        "    print('checking compatibility of loaded testset and model...')\n",
        "    modelinputshape = model.layers[0].input_shape\n",
        "    reshaped = []\n",
        "    global X_test\n",
        "\n",
        "    if modelinputshape[1:] == X_test.shape[1:]:\n",
        "        print('testset and model compatible, no need to reshape!')\n",
        "    else:\n",
        "        print('testset and model incompatible, reshaping testset to match model...')\n",
        "        for i in X_test:\n",
        "            i = i.reshape(X_test.shape[1], X_test.shape[2])\n",
        "            i = cv2.resize(i, (modelinputshape[1], modelinputshape[2]))\n",
        "            reshaped.append(i)\n",
        "        reshaped = np.array(reshaped).reshape(-1, modelinputshape[1], modelinputshape[2], modelinputshape[3])\n",
        "        X_test = reshaped\n",
        "        print('reshaped testset!')\n",
        "\n",
        "\n",
        "'''prints an evaluation of the models performance on the loaded testset'''\n",
        "def print_evaluation():\n",
        "    eval = model.evaluate(X_test, y_test)\n",
        "\n",
        "    print('loss: {}, accuracy: {}'.format(eval[0], eval[1]))\n",
        "\n",
        "\n",
        "'''predicts a sample by its index in the testset, 0 would give the prediction\n",
        "for the first one etc.'''\n",
        "def predict_sample(sample_id):\n",
        "    img_array = np.array(X_test[sample_id]).reshape(-1, IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "    prediction = model.predict(img_array)\n",
        "    print('Model-Predictions: {},Index-Labels: {}'.format(prediction, y_test[sample_id]))\n",
        "\n",
        "\n",
        "'''predicts the classifications for a given range of indices (takes a list),\n",
        "if no range is given, it predicts the whole testset'''\n",
        "def predict_range(_range=None):\n",
        "    if _range is None:\n",
        "        _range = len(X_test)\n",
        "\n",
        "    predictions = model.predict(X_test[:_range])\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "'''returns a list of indices from X_test whose predictions by the model were wrong'''\n",
        "def get_false_predictions(_range=None):\n",
        "    if _range is None:\n",
        "        _range = len(X_test)\n",
        "    negatives = []\n",
        "    j = 0\n",
        "\n",
        "    print('predicting {} samples...'.format(_range))\n",
        "    predictions = model.predict(X_test[:_range])\n",
        "    print('got predictions! comparing...')\n",
        "\n",
        "    for i in predictions:\n",
        "        for classes in range(len(i)):\n",
        "            x = round(i[classes])\n",
        "            y = y_test[j, classes]\n",
        "            if x != y:\n",
        "                if j in negatives:\n",
        "                    continue\n",
        "                else:\n",
        "                    negatives.append(j)       \n",
        "        j += 1\n",
        "\n",
        "    print('Number of false predictions: {} of {} tested.'.format(len(negatives), _range))\n",
        "\n",
        "    return negatives\n",
        "\n",
        "\n",
        "'''returns the average prediction confidence of given indices from the testset'''\n",
        "def get_average_confidence(indices):\n",
        "    average_confidence = 0.0\n",
        "    counter = 0\n",
        "    for index in indices:\n",
        "        img_array = np.array(X_test[index]).reshape(-1, IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "        prediction = model.predict(img_array)\n",
        "        average_confidence += max(max(prediction))\n",
        "        counter += 1\n",
        "    average_confidence /= counter\n",
        "\n",
        "    return average_confidence\n",
        "\n",
        "\n",
        "'''prints a summary of the architecture of the currently loaded model'''\n",
        "def print_summary():\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "'''plots the desired samples from testset by indices (takes a list) with correct\n",
        "and model predictions as the plot-title'''\n",
        "def plot_index_sample(indices):\n",
        "    for index in indices:\n",
        "      img_array = np.array(X_test[index]).reshape(-1, IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "      img = img_array * 255\n",
        "      img = img.reshape(IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "      img = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
        "      prediction = model.predict(img_array)\n",
        "\n",
        "      for i in range(len(y_test[index])):\n",
        "            if y_test[index, i] == 1:\n",
        "                correct_pred = i\n",
        "\n",
        "      fig = plt.figure('Index: {}, correct prediction: class{}, model-predictions: {}'.format(index, correct_pred ,prediction))\n",
        "      # the print is here for google colab, as it cant show the title there\n",
        "      print('Index: {}, correct prediction: class{}, model-predictions: {}'.format(index, correct_pred ,prediction))\n",
        "      plt.imshow(img)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "'''deep taylor decomposition-function'''\n",
        "def dtd(sample):\n",
        "    # Create analyzer\n",
        "    analyzer = innvestigate.create_analyzer('deep_taylor', strip_softmax(model))\n",
        "\n",
        "    # sample in format expected by model\n",
        "    x = sample\n",
        "\n",
        "    # Apply analyzer w.r.t. maximum activated output-neuron\n",
        "    a = analyzer.analyze(x)\n",
        "\n",
        "    # Aggregate along color channels and normalize to [-1, 1]\n",
        "    a = a.sum(axis=np.argmax(np.asarray(a.shape) == 3))\n",
        "    a /= np.max(np.abs(a))\n",
        "    a = a.reshape(IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "    return a\n",
        "\n",
        "\n",
        "'''guided backprop-function'''\n",
        "def guided_backprop(sample):\n",
        "    # Create analyzer\n",
        "    analyzer = innvestigate.create_analyzer('guided_backprop', strip_softmax(model))\n",
        "\n",
        "    # sample in format expected by model\n",
        "    x = sample\n",
        "\n",
        "    # Apply analyzer w.r.t. maximum activated output-neuron\n",
        "    a = analyzer.analyze(x)\n",
        "\n",
        "    a = a.reshape(IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "    a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return a\n",
        "\n",
        "\n",
        "'''patternnet-function'''\n",
        "def patternnet(sample):\n",
        "    # sample in format expected by model\n",
        "    x = sample\n",
        "\n",
        "    # Apply analyzer w.r.t. maximum activated output-neuron\n",
        "    # a = analyser.analyse(x)\n",
        "    a = pn_analyzer.analyze(x)\n",
        "\n",
        "    a = a.reshape(IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "    a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return a\n",
        "\n",
        "\n",
        "'''pattern attribution-function'''\n",
        "def patternattribution(sample):\n",
        "    # sample in format expected by model\n",
        "    x = sample\n",
        "\n",
        "    # Apply analyzer w.r.t. maximum activated output-neuron\n",
        "    # a = analyser.analyse(x)\n",
        "    a = pa_analyzer.analyze(x)\n",
        "\n",
        "    # Aggregate along color channels and normalize to [-1, 1]\n",
        "    a = a.sum(axis=np.argmax(np.asarray(a.shape) == 3))\n",
        "    a /= np.max(np.abs(a))\n",
        "    a = a.reshape(IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "    return a\n",
        "\n",
        "\n",
        "'''activation maximization-function'''\n",
        "def actmax(sample):\n",
        "    cams = []\n",
        "    for i in range(len(y_test[0])):\n",
        "        cam = visualize_activation(linear_model, utils.find_layer_idx(model, name_softmax_layer), filter_indices=i,\n",
        "                                   wrt_tensor=None, seed_input=sample, input_range=(0, 255), backprop_modifier=None,\n",
        "                                   grad_modifier=None, act_max_weight=1, lp_norm_weight=10, tv_weight=10)\n",
        "\n",
        "        cam = cam.reshape(IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "        cam = cv2.cvtColor(cam.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
        "        cams.append(cam)\n",
        "\n",
        "    return cams\n",
        "\n",
        "\n",
        "'''saliency-maps-function'''\n",
        "def saliency(sample):\n",
        "    cams = []\n",
        "    for i in range(len(y_test[0])):\n",
        "        cam = visualize_saliency(linear_model, utils.find_layer_idx(linear_model, name_softmax_layer), filter_indices=i,\n",
        "                                 seed_input=sample, wrt_tensor=None, backprop_modifier='guided', grad_modifier='relu',\n",
        "                                 keepdims=False)\n",
        "        cams.append(cam)\n",
        "\n",
        "    return cams\n",
        "\n",
        "\n",
        "'''gradcam-function'''\n",
        "def gradcam(sample):\n",
        "    cams = []\n",
        "    for i in range(len(y_test[0])):\n",
        "        cam = visualize_cam(linear_model, utils.find_layer_idx(linear_model, name_softmax_layer), filter_indices=i,\n",
        "                            seed_input=sample, penultimate_layer_idx=utils.find_layer_idx(linear_model, name_last_conv_layer),\n",
        "                            backprop_modifier='guided', grad_modifier=None)\n",
        "        cams.append(cam)\n",
        "\n",
        "    return cams\n",
        "\n",
        "\n",
        "'''gets sample_count number of filters (randomly) out of each given layer in the \n",
        "global inputs at the start of the script and saves them to the IMG_DIR'''\n",
        "def layered_actmax(sample_count):\n",
        "    for layer_nm in layerlist_for_layered_actmax:\n",
        "        layer_idx = utils.find_layer_idx(model, layer_nm)\n",
        "        num_filters = get_num_filters(model.layers[layer_idx])\n",
        "        drawn_filters = random.choices(np.arange(num_filters), k=sample_count)\n",
        "        for filter_id in drawn_filters:\n",
        "            img = visualize_activation(model, layer_idx, filter_indices=filter_id, input_modifiers=[Jitter(16)])\n",
        "            img = img.reshape(IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            plt.imshow(img, cmap='gray')\n",
        "            img_path = os.path.join(IMG_DIR, layer_nm + '_' + str(filter_id) + '.jpg')\n",
        "            plt.imsave(img_path, img)\n",
        "            print(f'Saved layer {layer_nm}/{filter_id} to file!')\n",
        "    print('done!')\n",
        "\n",
        "\n",
        "'''gets all the finished visualizations for vis, plots them and saves the \n",
        "plotted image to IMG_DIR'''\n",
        "def plot_vis(grads, actmaxs, sals, sample, correct_pred, sample_id='undefined'):\n",
        "    prediction = model.predict(sample)  # get model prediction for sample\n",
        "    '''prep sample'''\n",
        "    img = sample * 255\n",
        "    img = img.reshape(IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "    img = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    '''plot all vis-elements on same figure'''\n",
        "    fig, axes = plt.subplots(3, (len(grads)+1), figsize=(3+(4*len(grads)), 10))\n",
        "    # plt.subplots_adjust(wspace=0.25)  # margin between subplots\n",
        "    '''gradcam'''\n",
        "    axes[0, 0].imshow(img)  # what is shown in the subplot?\n",
        "    axes[0, 0].title.set_text('Input Image')  # title of the subplot\n",
        "    for grad in range(len(grads)):\n",
        "        axes[0, grad + 1].imshow(img)\n",
        "        i = axes[0, grad + 1].imshow(grads[grad], cmap='jet', alpha=0.9)  # generates an overlay over subplot at index 1\n",
        "        axes[0, grad + 1].title.set_text('gradCAM, Class{}'.format(grad))\n",
        "        divider = make_axes_locatable(\n",
        "            axes[0, grad + 1])  # helper to adjust the sizing of plot and corresponding colorbar\n",
        "        cax = divider.append_axes('right', size='5%', pad=0.05)  # helper to adjust the sizing of plot and corresp. cb\n",
        "        fig.colorbar(i, cax=cax)  # displays colorbar for overlay 'i'\n",
        "    '''actmax'''\n",
        "    axes[1, 0].imshow(img)\n",
        "    axes[1, 0].title.set_text('Input Image')\n",
        "    for act in range(len(actmaxs)):\n",
        "        axes[1, act + 1].imshow(actmaxs[act])\n",
        "        axes[1, act + 1].title.set_text('Activation Maximization, Class{}'.format(act))\n",
        "    '''saliency'''\n",
        "    axes[2, 0].imshow(img)\n",
        "    axes[2, 0].title.set_text('Input Image')\n",
        "    for sal in range(len(sals)):\n",
        "        axes[2, sal + 1].imshow(sals[sal], cmap='seismic', clim=(-1, 1))\n",
        "        axes[2, sal + 1].title.set_text('Saliency Map, Class{}'.format(sal))\n",
        "\n",
        "    labelstring = ''\n",
        "    for i in range(len(prediction[0])):\n",
        "        labelstring += ' Class {}: '.format(i)\n",
        "        labelstring += '{:5.3f}'.format(prediction[0, i])\n",
        "\n",
        "    plt.suptitle('Results for vis-library, Correct Class: {}, Model-Predictions:{}'.format(correct_pred, labelstring))\n",
        "\n",
        "    img_path = os.path.join(IMG_DIR, '{}_vis.png'.format(sample_id))\n",
        "\n",
        "    plt.savefig(img_path)\n",
        "\n",
        "\n",
        "'''gets all the finished visualizations for innvestigate, plots them and saves the \n",
        "plotted image to IMG_DIR'''\n",
        "def plot_innvestigate(gb, pn, pa, dtd, sample, correct_pred, sample_id='undefined'):\n",
        "    prediction = model.predict(sample)\n",
        "    '''prep sample'''\n",
        "    img = sample * 255\n",
        "    img = img.reshape(IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "    img = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
        "    gb = cv2.cvtColor(gb, cv2.COLOR_BGR2RGB)\n",
        "    pn = cv2.cvtColor(pn, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
        "    plt.subplots_adjust(wspace=0.25)\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].title.set_text('Input Image')\n",
        "    axes[1].imshow(gb)\n",
        "    axes[1].title.set_text('GuidedBackprop')\n",
        "    axes[2].imshow(pn)\n",
        "    axes[2].title.set_text('PatternNet')\n",
        "    axes[3].imshow(pa, cmap='seismic', clim=(-1, 1))\n",
        "    axes[3].title.set_text('PatternAttribution')\n",
        "    axes[4].imshow(dtd, cmap='seismic', clim=(-1, 1))\n",
        "    axes[4].title.set_text('DeepTaylor')\n",
        "\n",
        "    labelstring = ''\n",
        "    for i in range(len(prediction[0])):\n",
        "        labelstring += ' Class {}: '.format(i)\n",
        "        labelstring += '{:5.3f}'.format(prediction[0, i])\n",
        "\n",
        "    plt.suptitle('Results for Innvestigate-library, Correct Class: {}, Model-Predictions:{}'.format(correct_pred,\n",
        "                                                                                                    labelstring))\n",
        "\n",
        "    img_path = os.path.join(IMG_DIR, '{}_innvestigate.png'.format(sample_id))\n",
        "\n",
        "    plt.savefig(img_path)\n",
        "\n",
        "\n",
        "'''takes a list of indices from the testset, hands all necessary information to\n",
        "all the visualization-implementations, gathers the results and hands them to\n",
        "the plotting functions'''\n",
        "def plot_index(samples):\n",
        "    for sample in samples:\n",
        "        img_array = np.array(X_test[sample]).reshape(-1, IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "        for i in range(len(y_test[sample])):\n",
        "            if y_test[sample, i] == 1:\n",
        "                correct_pred = i\n",
        "\n",
        "        print('gathering and plotting visualizations for index {} (vis)...'.format(sample))\n",
        "        plot_vis(gradcam(img_array), actmax(img_array), saliency(img_array), img_array, correct_pred, sample)\n",
        "\n",
        "        print('gathering and plotting visualizations for index {} (innvestigate)...'.format(sample))\n",
        "        plot_innvestigate(guided_backprop(img_array), patternnet(img_array),\n",
        "                          patternattribution(img_array), dtd(img_array), img_array, correct_pred, sample)\n",
        "\n",
        "\n",
        "'''used for displaying the gradients of a specific external image by its path,\n",
        "handles data just like plot_index() also takes a name that the image is saved \n",
        "as, since there is no ground truth, only the models prediction, it will hand \n",
        "'no ground-truth available' as ground truth information to the plotting functions'''\n",
        "def plot_image(path, name='external_image'):\n",
        "    if IMG_DEPTH == 1:\n",
        "        img_array = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)  # convert to gs array\n",
        "    if IMG_DEPTH == 3:\n",
        "        img_array = cv2.imread(str(path))  # convert to array\n",
        "\n",
        "    img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "    img_array = np.array(img_array).reshape(-1, IMG_SIZE, IMG_SIZE, IMG_DEPTH)\n",
        "    img_array = img_array / 255\n",
        "\n",
        "    correct_pred = 'no ground-truth available'\n",
        "\n",
        "    print('gathering and plotting visualizations for your image (vis)...')\n",
        "    plot_vis(gradcam(img_array), actmax(img_array), saliency(img_array), img_array, correct_pred, str(name))\n",
        "\n",
        "    print('gathering and plotting visualizations for your image (innvestigate)...')\n",
        "    plot_innvestigate(guided_backprop(img_array), patternnet(img_array),\n",
        "                      patternattribution(img_array), dtd(img_array), img_array, correct_pred, str(name))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ap54NzlS8R",
        "colab_type": "text"
      },
      "source": [
        "# some usage-examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSZOI8tOlhL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will check if the loaded testdata is compatile with the loaded model and\n",
        "# make it if not\n",
        "\n",
        "reshape_testset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AO9Cj7NvBpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will print loss and accuracy of the loaded model \n",
        "# (calculated using the testdata) \n",
        "\n",
        "print_evaluation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua5bu48KvA-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will print an overview of the architecture of the loaded model\n",
        "\n",
        "print_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cJJpifUtFk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will plot and safe the images for indices 10, 34 and 788 from the testset\n",
        "\n",
        "plot_index([10, 34, 788])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykmFvg2WqFsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will plot and safe ALL indices of images the model predicted falsely\n",
        "# this might lead to warnings as a lot of figures have to be drawn simultaneously\n",
        "\n",
        "plot_index(get_false_predictions())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwwP2FTB-SdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will plot the result for an image called 'test.PNG' in the given path\n",
        "# and safe it as 'test_name', note that because it is an external example,\n",
        "# there is no ground truth that can be displayed in the plots title\n",
        "\n",
        "plot_image('/content/test.PNG', 'test_name')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yIqul6D6W9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will return the average confidence of the models predictions for the\n",
        "# first 100 images from the testset\n",
        "\n",
        "get_average_confidence(range(0, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq1XO4NvtGDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will return the average confidence of the models predictions for\n",
        "# all images the model predicted falsely\n",
        "get_average_confidence(get_false_predictions())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp0vwYLCt6RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will print the models prediction for the first image from the testset\n",
        "# including its ground truth for comparison\n",
        "\n",
        "predict_sample(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdh_MdSxsL09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will return a numpy array object with the first models predictions\n",
        "# for the first 100 images from the testset (it doesnt give the ground truth tho)\n",
        "\n",
        "predict_range(100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}