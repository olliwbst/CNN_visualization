import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout
from keras.callbacks import TensorBoard
from keras.callbacks import ModelCheckpoint

'''settable parameters start'''
TBNAME = 'tensorboard_metrics'  # name for tensorboard-file
model_filepath = 'model_{epoch:02d}_{val_accuracy:.4f}.h5'

X_train_PATH = 'abovelayershifting_X_213_1.npy'  # train-features
y_train_PATH = 'abovelayershifting_y_213_1.npy'  # train-labels

X_test_PATH = 'abovelayershifting_X_test_213_1.npy'  # test-features
y_test_PATH = 'abovelayershifting_y_test_213_1.npy'  # test-labels
'''settable parameters end'''

# trainingdata arrays, set the paths to the correct sets generated by data_preparation.py
print('loading traindata...')
X = np.load(X_train_PATH)
y = np.load(y_train_PATH)
print('length of traindata, needs to be equal: ', len(X), len(y))

print('loading testdata...')
X_test = np.load(X_test_PATH)
y_test = np.load(y_test_PATH)
print('length of testdata, needs to be equal: ', len(X_test), len(y_test))

# reshape labels to support multiple classes
y = keras.utils.to_categorical(y)
y_test = keras.utils.to_categorical(y_test)

X = X / 255.0  # normalize data because 255 is max pixelvalue
X_test = X_test / 255.0

print('finished loading data...')

'''MODEL STARTS HERE'''

model = Sequential()

# Block 1
model.add(Conv2D(96, (3, 3),
                 activation='relu',
                 padding='same',
                 name='block1_conv1',
                 input_shape=X.shape[1:]))
model.add(Conv2D(96, (3, 3),
                 activation='relu',
                 padding='same',
                 name='block1_conv2'))
model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))
model.add(Dropout(0.25))

# Block 2
model.add(Conv2D(96, (3, 3),
                 activation='relu',
                 padding='same',
                 name='block2_conv1'))
model.add(Conv2D(96, (3, 3),
                 activation='relu',
                 padding='same',
                 name='block2_conv2'))
model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))
model.add(Dropout(0.25))

# Classification block
model.add(Flatten(name='flatten'))
model.add(Dense(128, activation='relu', name='fc1'))
model.add(Dense(128, activation='relu', name='fc2'))
model.add(Dense(2, activation='softmax', name='predictions'))

adam = keras.optimizers.Adam(lr=0.0001)

model.compile(loss='categorical_crossentropy',
              optimizer=adam,
              metrics=['accuracy'])

'''CALLBACKS'''
# tensorboard
tensorboard = TensorBoard(log_dir="logs/{}".format(TBNAME))
# tensorboard --logdir=logs/  to initialize the board from working dir

# checkpoint
checkpoint = ModelCheckpoint(model_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

model.fit(X, y,
          batch_size=64,
          epochs=40,
          validation_data=(X_test, y_test),
          callbacks=[tensorboard, checkpoint])

'''MODEL ENDS HERE'''

'''
things to note:

following things are mandatory for compatibility with the framework:
-line 47, input_shape. leave as is (needs to be first layer)
-line 71, activation need to stay softmax, number of neurons needs
to be set to number of classes the problem has, in case you change the name
also change it in visualization-block (settable parameters)
-line 75, use a loss function that works with more than two classes
-at least one maxpooled convlayer-combination where the conv before the pool can
be used as gradCAM input-parameter, if multiple pooled conv use the one closest 
to final classification layer, here this would be 'block2_conv2' and set the
parameter in visualization-block to same name again
-if you want to use the layered_actmax function of visualization block you need
to change the names of all layers you want to extract filters of manually for
now so eighter set them like here for those layers or use print_summary() there
to see the generated layernames

everything besides that between the MODEL START and END tags is freely 
adjustable to the datasets needs

the implemented combination of architecture and hyperparameters here has to be
proven quite effective for relatively simple problems and, more importantly,
works with all the visualization algorithms
'''

print('done.')
